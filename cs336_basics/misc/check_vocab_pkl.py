import pickle

vocab_pkl_path = "/mnt/disk3/yusheng/assignment1-basics/data/tokenizer/vocab_10000.pkl"
expected_vocab_size = 10000

with open(vocab_pkl_path, "rb") as f:
    vocab = pickle.load(f)

print(f"âœ… Loaded vocab from: {vocab_pkl_path}")
print(f"ğŸ”¢ Vocab size: {len(vocab)}")

key_types = set(type(k) for k in vocab.keys())
value_types = set(type(v) for v in vocab.values())

print(f"ğŸ”‘ Key types: {key_types}")
print(f"ğŸ”¤ Value types: {value_types}")

try:
    max_id = max(vocab.keys())
    print(f"ğŸ“ˆ Max vocab ID: {max_id}")
except Exception as e:
    print(f"âš ï¸ Cannot compute max key: {e}")

if expected_vocab_size is not None:
    if len(vocab) != expected_vocab_size:
        print(f"âŒ Vocab size ({len(vocab)}) != expected ({expected_vocab_size})")
    else:
        print("âœ… Vocab size matches expected")
